{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iJkTiIBhSgy"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 kaggle.json\n",
        "!kaggle datasets download  'kazanova/sentiment140'\n",
        "!unzip sentiment140.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "PubBiCCCOzRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import bz2\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification"
      ],
      "metadata": {
        "id": "rWGyI_UwO1TA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    text=text.lower()\n",
        "    text= re.sub(r'(.)1+', r'1', text) #REPEATING CHARS\n",
        "    text=re.sub('((www.[^s]+)|(https?://[^s]+))',' ',text) #URLS\n",
        "    text=re.sub('[0-9]+', '', text) #NUMBERS\n",
        "    text=\" \".join(filter(lambda x:x[0]!='@', text.split())) #REPLY\n",
        "    return text"
      ],
      "metadata": {
        "id": "Xrtn-B2iO2He"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('./training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1',names=['label','ids','date','flag','user','text']).sample(frac = 1).reset_index(drop=True)\n",
        "df['text']=df['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "B9-AUV6RHV_m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=df.iloc[:200000]\n",
        "test_data=df.iloc[200000:250000]\n",
        "del df"
      ],
      "metadata": {
        "id": "tKDh_-rnO46R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length=64\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = max_length)"
      ],
      "metadata": {
        "id": "gvaS9VMoO6Py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row=self.df.iloc[idx]\n",
        "        input_ids=torch.tensor(tokenizer.encode(row['text'],padding='max_length',max_length=max_length,truncation=True))\n",
        "        attention_mask=torch.where(input_ids!=1,False,True)\n",
        "        return {'input_ids':input_ids,\n",
        "         'attention_mask': attention_mask,\n",
        "         'label':torch.tensor(0.0 if row['label']==0 else 1.0)}"
      ],
      "metadata": {
        "id": "2OagpNkyO7uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_p=SentimentDataset(train_data)\n",
        "test_p=SentimentDataset(test_data)"
      ],
      "metadata": {
        "id": "1IOJcJAfO8-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Sentiment_Model(torch.nn.Module):\n",
        "    def __init__(self, embed_dim=64,max_seq_len=max_length):\n",
        "        super(Sentiment_Model, self).__init__()\n",
        "        self.input_embeddings = nn.Embedding(len(tokenizer), embed_dim)\n",
        "        self.lstm1 = nn.LSTM(embed_dim, embed_dim//2,batch_first=True, num_layers=1,  dropout=0.1, bidirectional=True)\n",
        "        self.dense = nn.Linear(embed_dim, 1)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        input_embeddings = self.input_embeddings(input_ids)\n",
        "        lstm_output, (hn, cn) = self.lstm1(input_embeddings)\n",
        "        mean_output = lstm_output.mean(dim=1)\n",
        "\n",
        "        outputs = self.dense(mean_output)\n",
        "\n",
        "        return outputs"
      ],
      "metadata": {
        "id": "H0ezfCDRPe4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sentiment_Model()\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# device='cpu'\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "NODVEtVAO-sy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_p,batch_size=32,shuffle=True)\n",
        "test_loader=DataLoader(test_p,batch_size=32,shuffle=True)"
      ],
      "metadata": {
        "id": "s_rKez3FPC7W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mini_batch(samples):\n",
        "    input_ids = [s['input_ids'] for s in samples]\n",
        "    attention_mask = [(s['attention_mask']) for s in samples]\n",
        "    label = [s['label'] for s in samples]\n",
        "    l=max_length\n",
        "    input_ids=torch.stack(input_ids)[:,:l]\n",
        "    attention_mask=torch.stack(attention_mask)[:,:l]\n",
        "    label=torch.stack(label)\n",
        "    return input_ids, attention_mask, label"
      ],
      "metadata": {
        "id": "zk_L_H75PFj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(num_epochs=30):\n",
        "    criterion= nn.BCEWithLogitsLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_corrects=0.0\n",
        "        train_total=0.0\n",
        "        test_corrects=0.0\n",
        "        test_total=0.0\n",
        "        for batch in tqdm.tqdm(train_loader):\n",
        "            input_ids=batch['input_ids']\n",
        "            attention_mask=batch['attention_mask'].T\n",
        "            labels=batch['label']\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(input_ids).view(-1,)\n",
        "            loss = criterion(outputs,labels)\n",
        "            train_loss += loss.item()\n",
        "            train_corrects+=torch.sum((outputs>0.5).float()==labels).item()\n",
        "            train_total+=outputs.size(0)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids=batch['input_ids']\n",
        "                attention_mask=batch['attention_mask'].T\n",
        "                labels=batch['label']\n",
        "\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(input_ids).view(-1,)\n",
        "                loss = criterion(outputs,labels)\n",
        "                test_corrects+=torch.sum((outputs>0.5).float()==labels).item()\n",
        "                test_total+=outputs.size(0)\n",
        "                valid_loss += loss.item()\n",
        "        avg_valid_loss = valid_loss / len(test_loader)\n",
        "\n",
        "        if avg_valid_loss < best_valid_loss:\n",
        "            best_valid_loss = avg_valid_loss\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f},Train acc: {train_corrects/train_total}, Valid Loss: {avg_valid_loss:.4f},Valid acc: {test_corrects/test_total}\")"
      ],
      "metadata": {
        "id": "7DOKzmSbPG2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()"
      ],
      "metadata": {
        "id": "U9D4rae6PIbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline(input_):\n",
        "  input_ids=torch.tensor([tokenizer.encode(input_,padding='max_length',max_length=max_length,truncation=True)]).to(device)\n",
        "  # print(input_ids)\n",
        "  outputs=model(input_ids)[0].argmax(dim=-1)\n",
        "  return outputs"
      ],
      "metadata": {
        "id": "F-QPOLTyPJjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()"
      ],
      "metadata": {
        "id": "j3qELJSihRWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(run_pipeline('I feel so good'))\n",
        "print(run_pipeline('I lost my mother today. I miss her. I wish I could have her back'))"
      ],
      "metadata": {
        "id": "TkM7wxVSZlE4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}