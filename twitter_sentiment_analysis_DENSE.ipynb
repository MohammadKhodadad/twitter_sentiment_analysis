{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5iJkTiIBhSgy"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 kaggle.json\n",
        "!kaggle datasets download  'kazanova/sentiment140'\n",
        "!unzip sentiment140.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PubBiCCCOzRM"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWGyI_UwO1TA"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import bz2\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import RobertaTokenizerFast, RobertaForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xrtn-B2iO2He"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    text=text.lower()\n",
        "    text= re.sub(r'(.)1+', r'1', text) #REPEATING CHARS\n",
        "    text=re.sub('((www.[^s]+)|(https?://[^s]+))',' ',text) #URLS\n",
        "    text=re.sub('[0-9]+', '', text) #NUMBERS\n",
        "    text=\" \".join(filter(lambda x:x[0]!='@', text.split())) #REPLY\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9-AUV6RHV_m"
      },
      "outputs": [],
      "source": [
        "df=pd.read_csv('./training.1600000.processed.noemoticon.csv',encoding='ISO-8859-1',names=['label','ids','date','flag','user','text']).sample(frac = 1).reset_index(drop=True)\n",
        "df['text']=df['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKDh_-rnO46R"
      },
      "outputs": [],
      "source": [
        "train_data=df.iloc[:200000]\n",
        "test_data=df.iloc[250000:300000]\n",
        "del df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gvaS9VMoO6Py"
      },
      "outputs": [],
      "source": [
        "max_length=64\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained('roberta-base', max_length = max_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OagpNkyO7uj"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "        self.df = df\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row=self.df.iloc[idx]\n",
        "        input_ids=torch.tensor(tokenizer.encode(row['text'],padding='max_length',max_length=max_length,truncation=True))\n",
        "        attention_mask=torch.where(input_ids!=1,False,True)\n",
        "        return {'input_ids':input_ids,\n",
        "         'attention_mask': attention_mask,\n",
        "         'label':torch.tensor(0.0 if row['label']==0 else 1.0)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IOJcJAfO8-I"
      },
      "outputs": [],
      "source": [
        "train_p=SentimentDataset(train_data)\n",
        "test_p=SentimentDataset(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H0ezfCDRPe4i"
      },
      "outputs": [],
      "source": [
        "class Sentiment_Model(torch.nn.Module):\n",
        "    def __init__(self, embed_dim=64,max_seq_len=max_length,dim1=32):\n",
        "        super(Sentiment_Model, self).__init__()\n",
        "        self.input_embeddings = nn.Embedding(len(tokenizer), embed_dim)\n",
        "        self.dense1 = nn.Linear(embed_dim, dim1)\n",
        "        self.bn1=nn.BatchNorm1d(64)\n",
        "        self.dp1=nn.Dropout(0.4)\n",
        "        self.dense = nn.Linear(dim1, 1)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        input_embeddings = self.input_embeddings(input_ids)\n",
        "        dense1_output = F.relu(self.dp1(self.bn1(self.dense1(input_embeddings))))\n",
        "        mean_output = dense1_output.mean(dim=1)\n",
        "        outputs = self.dense(mean_output)\n",
        "\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s_rKez3FPC7W"
      },
      "outputs": [],
      "source": [
        "train_loader=DataLoader(train_p,batch_size=32,shuffle=True)\n",
        "test_loader=DataLoader(test_p,batch_size=32,shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zk_L_H75PFj1"
      },
      "outputs": [],
      "source": [
        "def create_mini_batch(samples):\n",
        "    input_ids = [s['input_ids'] for s in samples]\n",
        "    attention_mask = [(s['attention_mask']) for s in samples]\n",
        "    label = [s['label'] for s in samples]\n",
        "    input_ids=torch.stack(input_ids)[:,:l]\n",
        "    attention_mask=torch.stack(attention_mask)[:,:l]\n",
        "    label=torch.stack(label)\n",
        "    return input_ids, attention_mask, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wGj_lMPz-EZE"
      },
      "outputs": [],
      "source": [
        "history=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7DOKzmSbPG2S"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs=10,learning_rate=1e-3,dim1=32,embed_dim=32, optimizer_name='adam'):\n",
        "    criterion= nn.BCEWithLogitsLoss()\n",
        "    if optimizer_name=='adam':\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    if optimizer_name =='sgd':\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "    if optimizer_name =='rmsprop':\n",
        "      optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
        "    best_valid_loss = float('inf')\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        train_corrects=0.0\n",
        "        train_total=0.0\n",
        "        test_corrects=0.0\n",
        "        test_total=0.0\n",
        "        for batch in tqdm.tqdm(train_loader):\n",
        "            input_ids=batch['input_ids']\n",
        "            attention_mask=batch['attention_mask'].T\n",
        "            labels=batch['label']\n",
        "\n",
        "            input_ids = input_ids.to(device)\n",
        "            attention_mask = attention_mask.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(input_ids).view(-1,)\n",
        "            loss = criterion(outputs,labels)\n",
        "            train_loss += loss.item()\n",
        "            train_corrects+=torch.sum((outputs>0.5).float()==labels).item()\n",
        "            train_total+=outputs.size(0)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                input_ids=batch['input_ids']\n",
        "                attention_mask=batch['attention_mask'].T\n",
        "                labels=batch['label']\n",
        "\n",
        "                input_ids = input_ids.to(device)\n",
        "                attention_mask = attention_mask.to(device)\n",
        "                labels = labels.to(device)\n",
        "                outputs = model(input_ids).view(-1,)\n",
        "                loss = criterion(outputs,labels)\n",
        "                test_corrects+=torch.sum((outputs>0.5).float()==labels).item()\n",
        "                test_total+=outputs.size(0)\n",
        "                valid_loss += loss.item()\n",
        "        avg_valid_loss = valid_loss / len(test_loader)\n",
        "\n",
        "        if avg_valid_loss < best_valid_loss:\n",
        "            best_valid_loss = avg_valid_loss\n",
        "            torch.save(model.state_dict(), \"best_model.pt\")\n",
        "        history.append([epoch,learning_rate,dim1,embed_dim,optimizer,avg_train_loss,train_corrects/train_total,avg_valid_loss,test_corrects/test_total])\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}: \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f},Train acc: {train_corrects/train_total}, Valid Loss: {avg_valid_loss:.4f},Valid acc: {test_corrects/test_total}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP3w5qNc_CPD"
      },
      "outputs": [],
      "source": [
        "# for dim1 in [16,4,8,32,64]:\n",
        "#   for learning_rate in[1e-1,1e-2,1e-3,1e-4]:\n",
        "#     for embed_dim in [16,8,4,32,64]:\n",
        "for dim1 in [32]:\n",
        "  for learning_rate in[1e-2]:\n",
        "    for embed_dim in [128]:\n",
        "      for optimizer_name in ['rmsprop']:\n",
        "        model=Sentiment_Model(embed_dim=embed_dim,dim1=dim1)\n",
        "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "        # device='cpu'\n",
        "        model.to(device)\n",
        "        train(100,learning_rate,dim1,embed_dim,optimizer_name)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history=pd.DataFrame(history,columns=['epoch','learning_rate','dim1','embed_dim','optimizer','avg_train_loss','train_acc','avg_valid_loss','test_acc'])"
      ],
      "metadata": {
        "id": "hKfZSV8JRDVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data: Replace this with your actual data\n",
        "epochs = list(range(0, history.shape[0]))\n",
        "train_acc = history['train_acc']\n",
        "test_acc = history['test_acc']\n",
        "\n",
        "# Create a figure with both train and test loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_acc, label='Train Acc', color='blue', marker='o', linestyle='-')\n",
        "plt.plot(epochs, test_acc, label='Test Acc', color='red', marker='s', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Train and Test Accuracy History')\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.legend()\n",
        "\n",
        "# Save or display the combined figure\n",
        "plt.savefig('combined_loss_figure.svg', format='svg')  # To save as an image file\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZBOn1oiWAjlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import plotly.graph_objects as go\n",
        "\n",
        "# Sample data: Replace this with your actual data\n",
        "epochs = list(range(1, 11))\n",
        "train_loss = history['avg_train_loss']\n",
        "test_loss = history['avg_valid_loss']\n",
        "\n",
        "# Create a figure for train loss\n",
        "train_loss_fig = go.Figure()\n",
        "train_loss_fig.add_trace(go.Scatter(x=epochs, y=train_loss, mode='lines+markers', name='Train Loss'))\n",
        "train_loss_fig.update_layout(\n",
        "    title=\"Train Loss History\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Loss\",\n",
        ")\n",
        "\n",
        "# Create a figure for test loss\n",
        "test_loss_fig = go.Figure()\n",
        "test_loss_fig.add_trace(go.Scatter(x=epochs, y=test_loss, mode='lines+markers', name='Test Loss'))\n",
        "test_loss_fig.update_layout(\n",
        "    title=\"Test Loss History\",\n",
        "    xaxis_title=\"Epoch\",\n",
        "    yaxis_title=\"Loss\",\n",
        ")\n",
        "\n",
        "# Show the train and test loss figures\n",
        "train_loss_fig.show()\n",
        "test_loss_fig.show()"
      ],
      "metadata": {
        "id": "3aLSu4QQRT7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data: Replace this with your actual data\n",
        "epochs = list(range(0, history.shape[0]))\n",
        "train_loss = history['train_acc']\n",
        "test_loss = history['test_acc']\n",
        "\n",
        "# Create a figure for train loss\n",
        "# Create a figure with both train and test loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, train_loss, label='Train Loss', color='blue', marker='o', linestyle='-')\n",
        "plt.plot(epochs, test_loss, label='Test Loss', color='red', marker='s', linestyle='--')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Train and Test Loss History')\n",
        "plt.grid(True, alpha=0.2)\n",
        "plt.legend()\n",
        "\n",
        "# Save or display the combined figure\n",
        "plt.savefig('combined_loss_figure.png')  # To save as an image file\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nnjjZY15rKg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jcr0LC2sr3f5"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}